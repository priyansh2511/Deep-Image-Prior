{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.metrics import mse\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.backend import set_session\n",
        "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, BatchNormalization, ZeroPadding2D, UpSampling2D, Input, Lambda, multiply, Input, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "X39EcxgAXZO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70bRb9uzgWq6"
      },
      "outputs": [],
      "source": [
        "def ConvertImage(image, dim=32):\n",
        "    x_cut = image.size[0] - image.size[0] % dim\n",
        "    y_cut = image.size[1] - image.size[1] % dim\n",
        "\n",
        "    cropBox = []\n",
        "    cropBox.append(int((image.size[0] - x_cut) / 2))\n",
        "    cropBox.append(int((image.size[1] - y_cut) / 2))\n",
        "    cropBox.append(int((image.size[0] + x_cut) / 2))\n",
        "    cropBox.append(int((image.size[1] + y_cut) / 2))\n",
        "\n",
        "    img_cropped = image.crop(cropBox)\n",
        "    img_cropped = img_to_array(img_cropped)\n",
        "    img_cropped = (np.expand_dims(img_cropped, axis=0).astype('float32'))/255\n",
        "    return img_cropped\n",
        "\n",
        "\n",
        "def add_noise(image, sigma):\n",
        "    noise = np.clip(image + np.random.normal(scale=sigma, size=image.shape), 0, 1).astype(np.float32)\n",
        "    return noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqrI-7ZFGEiw"
      },
      "outputs": [],
      "source": [
        "class Hourglass:\n",
        "    def __init__(self, in_size, in_channel, out_channel, nu, nd, ns, ku,kd, ks,upsample='nearest'):\n",
        "        self.in_size = in_size\n",
        "        self.in_channel = in_channel\n",
        "        self.out_channel = out_channel\n",
        "        self.nu = nu\n",
        "        self.nd = nd\n",
        "        self.ns = ns\n",
        "        self.ku = ku\n",
        "        self.kd = kd\n",
        "        self.ks = ks\n",
        "        self.upsample = upsample\n",
        "        self.use_bias = True\n",
        "\n",
        "    def up_sample(self, x, size=2):\n",
        "        index = x.shape\n",
        "        new_w = int(round(index[1] * size))\n",
        "        new_h = int(round(index[2] * size))\n",
        "        return tf.image.resize(x, [new_w, new_h], method=tf.image.ResizeMethod.BILINEAR);\n",
        "\n",
        "    def down(self, x, n, k, use_bias=True):\n",
        "        pad_size = int((k - 1) / 2)\n",
        "        x = tf.pad(x, paddings=[[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]], mode='REFLECT')\n",
        "        x = Conv2D(n, k, strides=2, use_bias=use_bias)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        x = tf.pad(x, paddings=[[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]], mode='REFLECT')\n",
        "        x = Conv2D(n, k, strides=1, use_bias=use_bias)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "        return x\n",
        "\n",
        "    def skip(self, x, n, k, use_bias=True):\n",
        "        pad_size = int((k - 1) / 2)\n",
        "        x = tf.pad(x, paddings=[[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]], mode='REFLECT')\n",
        "        x = Conv2D(n, k, strides=1, use_bias=use_bias)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "        return x\n",
        "\n",
        "    def up(self, x, n, k, upsample_mode, use_bias=True):\n",
        "        x = BatchNormalization()(x)\n",
        "        pad_size = int((k - 1) / 2)\n",
        "        x = tf.pad(x, paddings=[[0, 0], [pad_size, pad_size], [pad_size, pad_size], [0, 0]], mode='REFLECT')\n",
        "        x = Conv2D(n, k, strides=1, use_bias=use_bias)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        x = Conv2D(n, 1, strides=1, use_bias=use_bias)(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(0.2)(x)\n",
        "\n",
        "        x = self.up_sample(x, 2)\n",
        "        return x\n",
        "\n",
        "    def model_structure(self):\n",
        "        width, height = self.in_size\n",
        "        input = Input((width, height, self.in_channel))\n",
        "        x = input\n",
        "        n = 5\n",
        "        skips = []\n",
        "        for i in range(n):\n",
        "            x = self.down(x, self.nd[i], self.kd[i], self.use_bias)\n",
        "            if self.ns[i] != 0:\n",
        "                skip = self.skip(x, self.ns[i], self.ks[i], self.use_bias)\n",
        "                skips.append(skip)\n",
        "\n",
        "        x = self.up(x, self.nu[n - 1], self.ku[n - 1], self.upsample, self.use_bias)\n",
        "        skips = skips[::-1]\n",
        "        for i in range(n - 1):\n",
        "            j = (n - 1)- i \n",
        "            if i != 0:\n",
        "                x = concatenate([x, skips[i+1]], axis=-1)\n",
        "            x = self.up(x, self.nu[j-1], self.ku[j-1],self.upsample, self.use_bias)\n",
        "\n",
        "        output = Conv2D(self.out_channel, 1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=input, outputs=output)\n",
        "        return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRA9289cR19q"
      },
      "outputs": [],
      "source": [
        "\n",
        "## environment options\n",
        "image_path = 'F16_GT.png'\n",
        "\n",
        "## experiment options\n",
        "sigma = 1. / 30\n",
        "method = 'random'\n",
        "input_channel = 3\n",
        "lr = 0.01\n",
        "num_iter = 5000\n",
        "\n",
        "### load data\n",
        "img = load_img(image_path)\n",
        "x = ConvertImage(img)\n",
        "x = add_noise(x, 25 / 255.)\n",
        "array_to_img(x[0]).save('original.png')\n",
        "    \n",
        "\n",
        "### build code z\n",
        "b, w, h, c = x.shape\n",
        "\n",
        "### build model\n",
        "layers = Hourglass((w, h), input_channel, c,\n",
        "                      nu=[128, 128, 128, 128, 128],\n",
        "                      nd=[128, 128, 128, 128, 128],\n",
        "                      ns=[4, 4, 4, 4, 128],\n",
        "                      ku=[3, 3, 3, 3, 3],\n",
        "                      kd=[3, 3, 3, 3, 3],\n",
        "                      ks=[1, 1, 1, 1, 1],\n",
        "                      upsample='bilinear'\n",
        "                      )\n",
        "\n",
        "model = layers.model_structure()\n",
        "model.compile(optimizer=Adam(lr=lr), loss=mse)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#z = make_noise(method, input_channel, (w, h))\n",
        "z = np.random.uniform(0, 0.1, size=(1,w,h,input_channel))\n",
        "losses = []\n",
        "for i in range(num_iter+1):\n",
        "    temp = z + np.random.normal(0, sigma, size = z.shape)\n",
        "    loss = model.train_on_batch(temp, x)\n",
        "    if i % 100 == 0:\n",
        "        print('iteration no.: %d ,loss : %f' % (i, loss))\n",
        "        y = model.predict_on_batch(z)\n",
        "        array_to_img(y[0]).save('%d.png' % i)\n",
        "\n"
      ],
      "metadata": {
        "id": "zfWo1T8NNQul"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}